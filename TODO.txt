BACKLOG:
* SimpleViewer: Try to detect cutouts and autoset the property.

* Try a new new seeding strategy with a nice screen space seed distribution.
** Perhaps write a small dev app to test various seeds and their first N random numbers?
*** Std dev of the pixel seeds and the pixel+neighbour seeds? As low as possible.
** Can Sobol / sample02 be used? Perhaps { sobol(x), INT_MAX / y }?
** Ideally it would also have a good distribution if the we compare every second pixel instead of direct neighbours.
** Parallel for that abstracts { local_init, body, local finish} using OpenMP?

* Light and BSDF samples in PRD
** Add emission, RGB + diffusitivity
** How do we handle coverage penetrations? Set BSDF weight to 1 and light radiance to 0, effectively negating the effects.
*** Add seperate float on PRD for coverage PDF. We can't inline it in the BSDF PDF because that would affect MIS.
*** And leave the MIS BSDF PDF alone, as the sample, from a MIS perspective, is still from the original surface.
*** Setup scene with transparent and masked planes blocking a light to test it.
** How do we handle direct light hits? Add emission to the monte carlo PRD.
*** Zero the BSDF sample.

* Reconstruction filters
** Albedo generator?
** Pr pixel.
** Linear.
** Mitchell.
** Filter neighbouring light samples before reconstruction.
*** Screen space photon mapping approach with MIS weights, then add a (recursive?) bilateral blur for everything not yet filtered.
** Autoencoder approach. Offline first.
*** Output 64 test images.
*** Depth, RGB, light sample, BSDF sample, normal, pixel offset, material ID and PDF and length of next sample.
*** Speed up training by train on 5x5 patches and then make it hierachically ourselves?

* Material improvements
** Metal specular tint should go to white at grazing angles.
** A Spherical Cap Preserving Parameterization for Spherical Distributions
** Importance sample improvement?
*** Pr pixel debug with pixel indication?
*** Gold, which is a specular metal, has a specular weight of 0.6, so it's (supposedly) 40% diffuse.
** IBL rho intensity.
*** Specularity increase is too strong.
*** Metals are too bright at grazing angles.
*** Perhaps computing the relation between GGX tint and rho would help figure out how much light scatters to the diffuse layer and how much the specular metal layers will reflect?
** Add coat.
*** http://jcgt.org/published/0003/04/03/paper-lowres.pdf
*** https://www.youtube.com/watch?v=4nKb9hRYbPA
*** Or just add a GGX layer on top with an iridescence parameter (red and blue fresnel offset relative to green.)
* VS compiler flags /debug:fastlink in VS2015. Use /GL (Enable link-time code generation), /LTCG (Use Link Time Code Generation) and /INCREMENTAL:NO (Disable Incremental Linking)
** Perhaps create cmake macros for setting up executables and libraries.
* Multiple cameras.
* Screenshot
** Render to offscreen buffer.
** Grab backbuffer on the CPU. (when the image is converged)
*** Request to composer or through the camera.
*** Expose certain backbuffer state pr camera/viewport in a renderer interface. Fx iteration_count, is_continuous_renderer and so on. Members that can be used to evaluate the 'doneness' of a backbuffer.
**** Investigate and potentially use C++ async concepts for this.
* Normals revisited
** Offset slightly along the geometric normal as well? To avoid self shadowing and hard edges on tesselated balls.
*** Or perhaps offset along the incoming direction? That one should obviously not intersect anything else.
** Bump mapping
*** Filter bumpmap mipmaps using Toksvig05, SGGX or AGAA NDF construction.
** 'Fix' the normals at edges. Let the shading normal lerp towards the geometric normal at grazing angles. (Offset normal by -view_dir until the dot product is 0.)
* BTDF
** Transmission factor.
*** Use IOR computed from specularity.
* Multiple scenes.
** Only nodes in a certain scene should be rendered.
** Should a scene node know if it is in a scene and in which? Store the root scene ID pr node?
* 3DS, STL and PLY loader.
* Serialize scene and models, perhaps just build GLFT importer and exporter at first. https://github.com/KhronosGroup/glTF

libs
* RtAudio wrapper - https://github.com/thestk/rtaudio
* Emscripten
* LuaJit - OpenSource (Fallback to interpretted Lua if the target architecture isn't supported.)
* ARGH! Command line passing tool - https://github.com/adishavit/argh
* MXNet for deep learning. Or just use cuDNN and ignore the abstractions.
* CUDA launch config - https://github.com/jaredhoberock/cuda_launch_config