* Texture / image VS debugging helpers. Can I do the same for UIDs?
* Compare old and new rng seed in cornell box. 1-32 frames. Send to ESI and Prashant.
* Revisit environment map (2D image) importance sampling. Try the new approach where pixels can be looked up almost immediatly.
** Cogwheel Distribution2D.
** Test cases
*** Test with different templates.
** EnvironmentMapDistribution:
*** Distribution2D with the sinus terms.
*** Filter per pixel importance with neighbouring pixel importances
** Environment map convolution application.
*** Material sampling, light sampling and MIS support.
** Integrate into OptiXRenderer.
** Cogwheel Distribution2D lookup table.
*** A cell is {ushort Begin, ushort End, float PDF}. 64bit aligned.
*** Compare with Distribution2D results.
** SSE / AVX optimizations.

BACKLOG:
* OptiXRenderer
** Better prime for seeding. One with less correlation.
** Verify that highest_area_light_index_updated in the OptiXRenderer behaves correctly.
** Half4 backbuffer in OptiXRenderer and render directly to a mapped DX resource.
** Logarithmic data upload: bitcount((frame_ID >> 3) + 1) == 1. Do we gain any performance from it?
** Filtering
* Materials revisited.
** Add coat.
* VS compiler flags /debug:fastlink in VS2015. Use /GL (Enable link-time code generation), /LTCG (Use Link Time Code Generation) and /INCREMENTAL:NO (Disable Incremental Linking)
  # if (MSVC14)
  #   message("/debug:fastlink")
  #   set(CMAKE_CXX_FLAGS_DEBUG /debug:fastlink CACHE INTERNAL "" FORCE) # https://blogs.msdn.microsoft.com/vcblog/2015/10/16/debugfastlink-for-vs2015-update-1/
  # endif()
* Multiple cameras.
** G-Buffer pr camera.
** Compose when all cameras are done.
* Screenshot
** Grab backbuffer on the CPU.
*** Request to composer or through the camera, not renderers
*** Expose certain backbuffer state pr camera/viewport in a renderer interface. Fx iteration_count, is_continuous_renderer and so on. Members that can be used to evaluate the 'doneness' of a backbuffer.
**** Investigate and potentially use C++ async concepts for this.
** Render to offscreen buffer.
* Normals revisited
** Bump mapping
*** Filter bumpmap mipmaps using Toksvig05, SGGX or AGAA NDF construction.
** 'Fix' the normals at edges. Let the shading normal lerp towards the geometric normal at grazing angles. (Offset normal by -view_dir until the dot product is 0.)
** Offset slightly along the geometric normal as well? To avoid self shadowing and hard edges on tesselated balls.
*** Or perhaps offset along the incoming direction? That one should obviously not intersect anything else.
* BTDF
** Transmission factor.
*** Use IOR computed from specularity.
* Multiple scenes.
** Only nodes in a certain scene should be rendered.
** Should a scene node know if it is in a scene and in which? Store the root scene ID pr node?
* 3DS, STL and PLY loader.
* Serialize scene and models.

libs
* Emscripten
* LuaJit - OpenSource (Fallback to interpretted Lua if the target architecture isn't supported.)
* OpenEXR + ZLib or TinyEXR.
